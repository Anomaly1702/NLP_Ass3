{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ced10323ca41432880435061d2390132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be85d98fe7dc4d0993074d6d7de502c6",
              "IPY_MODEL_7f3e20ad5d53428a8e1096fda6e6323d",
              "IPY_MODEL_601c3867edfb44f5a963e73195450f44"
            ],
            "layout": "IPY_MODEL_70eba14f52894e7a93096e4f936349d8"
          }
        },
        "be85d98fe7dc4d0993074d6d7de502c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56c62632281246a4bc62a853af6349b4",
            "placeholder": "​",
            "style": "IPY_MODEL_9706e64eb5e04bac81e5fd1096dcd68a",
            "value": "Map: 100%"
          }
        },
        "7f3e20ad5d53428a8e1096fda6e6323d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da48a1175bdb46258caba910468761ae",
            "max": 3350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fdb1d8ddd17047fdad1f36a8ee3190cd",
            "value": 3350
          }
        },
        "601c3867edfb44f5a963e73195450f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18fb17b671cb4fdab3e43f6f1b7dd930",
            "placeholder": "​",
            "style": "IPY_MODEL_5e4e2332268b49339fc7a026419a55de",
            "value": " 3350/3350 [01:11&lt;00:00, 47.33 examples/s]"
          }
        },
        "70eba14f52894e7a93096e4f936349d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "56c62632281246a4bc62a853af6349b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9706e64eb5e04bac81e5fd1096dcd68a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da48a1175bdb46258caba910468761ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdb1d8ddd17047fdad1f36a8ee3190cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18fb17b671cb4fdab3e43f6f1b7dd930": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e4e2332268b49339fc7a026419a55de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd1b01888602451282b9a66aeb4a00c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c46702c22514e13acdad91f5ba1aef6",
              "IPY_MODEL_ca26d2add161463c9e90e2b2e4110b03",
              "IPY_MODEL_e770c4b74e4c47e3816e9c7da4c0f067"
            ],
            "layout": "IPY_MODEL_181cdb5c2bbe46648833256762a5b35e"
          }
        },
        "4c46702c22514e13acdad91f5ba1aef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18205b78a8c14ecdb4e5a55a4dab7818",
            "placeholder": "​",
            "style": "IPY_MODEL_3b32db36043e423a856525994bbe6020",
            "value": "Map: 100%"
          }
        },
        "ca26d2add161463c9e90e2b2e4110b03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d790d07432004c03951005e9d39bdf41",
            "max": 1650,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afea395045ce4854962139463bc963f0",
            "value": 1650
          }
        },
        "e770c4b74e4c47e3816e9c7da4c0f067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2d9a7bf41fb467ebd1442c44b7e7e63",
            "placeholder": "​",
            "style": "IPY_MODEL_65a8a3d88e7e49b4a9cdc07b942bfc80",
            "value": " 1650/1650 [00:34&lt;00:00, 48.48 examples/s]"
          }
        },
        "181cdb5c2bbe46648833256762a5b35e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "18205b78a8c14ecdb4e5a55a4dab7818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b32db36043e423a856525994bbe6020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d790d07432004c03951005e9d39bdf41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afea395045ce4854962139463bc963f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2d9a7bf41fb467ebd1442c44b7e7e63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65a8a3d88e7e49b4a9cdc07b942bfc80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anomaly1702/NLP_Ass3/blob/main/Pujan_NLP_Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sumy\n",
        "!pip install transformers\n",
        "!pip install torchmetrics\n",
        "# train with custom data\n",
        "!pip install transformers datasets evaluate rouge_score\n",
        "import tqdm\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "46FmHPWPEX0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "603ed23c-4b4d-4d9a-d9f3-f6f217bbd812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sumy\n",
            "  Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 KB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from sumy) (3.8.1)\n",
            "Collecting docopt<0.7,>=0.6.1\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.9/dist-packages (from sumy) (2.27.1)\n",
            "Collecting pycountry>=18.2.23\n",
            "  Downloading pycountry-22.3.5.tar.gz (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting breadability>=0.1.20\n",
            "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.9/dist-packages (from breadability>=0.1.20->sumy) (4.0.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.9/dist-packages (from breadability>=0.1.20->sumy) (4.9.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk>=3.0.2->sumy) (4.65.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk>=3.0.2->sumy) (1.1.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk>=3.0.2->sumy) (2022.10.31)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk>=3.0.2->sumy) (8.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from pycountry>=18.2.23->sumy) (67.6.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.7.0->sumy) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.7.0->sumy) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.7.0->sumy) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.7.0->sumy) (2.0.12)\n",
            "Building wheels for collected packages: breadability, docopt, pycountry\n",
            "  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21708 sha256=369e0716608d0f4e1ab70d4d2d44ac285b862583c19a330e7f066c5350830235\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/9f/70/7795228568b81b57a8932755938da9fb1f291b0576752604aa\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13721 sha256=344c518f6fa1a320d75d9b8762da390d668b7a79f99428641c07f94918416ec6\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/4a/46/1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
            "  Building wheel for pycountry (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycountry: filename=pycountry-22.3.5-py2.py3-none-any.whl size=10681847 sha256=9fc0bcb445f3c9708d9d34f3a46cd6d9b5b551b6d0330340f65622680ec30cf2\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/15/92/e6dc85fcb0686c82e1edbcfdf80cfe4808c058813fed0baa8f\n",
            "Successfully built breadability docopt pycountry\n",
            "Installing collected packages: docopt, pycountry, breadability, sumy\n",
            "Successfully installed breadability-0.1.20 docopt-0.6.2 pycountry-22.3.5 sumy-0.11.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (2.0.0+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (3.10.7)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (1.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=ca2b8494a9712112b3e4b9220372a0029d40b31e871b7ce8a7f3c621926b5ffd\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/3d/39/09558097d3119ca0a4d462df68f22c6f3c1b345ac63a09b86e\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, rouge_score, responses, multiprocess, aiosignal, aiohttp, datasets, evaluate\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.11.0 dill-0.3.6 evaluate-0.4.0 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 rouge_score-0.1.2 xxhash-3.2.0 yarl-1.8.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sumy.parsers.plaintext import PlaintextParser\n",
        "# from sumy.summarizers.text_rank import TextRankSummarizer\n",
        "# from sumy.nlp.tokenizers import Tokenizer\n",
        "\n",
        "# # Sample text\n",
        "# text = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed non risus. Suspendisse lectus tortor, dignissim sit amet, adipiscing nec, ultricies sed, dolor. Cras elementum ultrices diam. Maecenas ligula massa, varius a, semper congue, euismod non, mi.\"\n",
        "\n",
        "# # Parse text\n",
        "# parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "\n",
        "# # Initialize summarizer\n",
        "# summarizer = TextRankSummarizer()\n",
        "\n",
        "# # Generate summary\n",
        "# summary = summarizer(parser.document, sentences_count=1)\n",
        "\n",
        "# # Print summary\n",
        "# for sentence in summary:\n",
        "#     print(sentence)\n"
      ],
      "metadata": {
        "id": "Hs4pZ5pzESej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are several datasets available for unsupervised text summarization, including:\n",
        "\n",
        "* CNN/Daily Mail: This is a dataset of news articles and corresponding summaries provided by CNN and the Daily Mail. The dataset can be downloaded from this link: https://cs.nyu.edu/~kcho/DMQA/.\n",
        "\n",
        "* Reddit TIFU: This is a dataset of posts from the subreddit TIFU (Today I Fucked Up) and their corresponding summaries. The dataset can be downloaded from this link: https://github.com/akashp1712/tifu-summarization-dataset.\n",
        "\n",
        "* WikiSum: This is a dataset of Wikipedia articles and their corresponding summaries. The dataset can be downloaded from this link: https://github.com/danieldeutsch/wikisum/tree/master/data.\n",
        "\n",
        "For the deep learning algorithm, one possible approach is to use a sequence-to-sequence (Seq2Seq) model with attention. Here's an example \n",
        "\n",
        "\n",
        "Implementation using TensorFlow:"
      ],
      "metadata": {
        "id": "xYCmICwUFekF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For unsupervised text summarization on medical data, there are a few publicly available datasets that you can use. Here are a few examples:\n",
        "\n",
        "* MIMIC-III: This is a dataset of electronic health records from critical care patients. The dataset contains clinical notes, such as discharge summaries, progress notes, and radiology reports, which can be used for text summarization. The dataset can be downloaded from this link: https://mimic.physionet.org/.\n",
        "\n",
        "* TREC Medical Records: This is a dataset of medical records from the TREC (Text REtrieval Conference) Clinical Decision Support Track. The dataset contains discharge summaries and pathology reports, which can be used for text summarization. The dataset can be downloaded from this link: https://ir.nist.gov/cdss/data/trec/trec_cds_2011.html.\n",
        "\n",
        "For the deep learning algorithm, you can use a similar approach as the one I described earlier. However, you may want to consider using a pre-trained language model, such as BERT or RoBERTa, to improve the performance of the summarization model. Here's an example implementation using the Hugging Face Transformers library and the MIMIC-III dataset:"
      ],
      "metadata": {
        "id": "eBMKhTk9FkzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "root_folder = '/content/drive/My Drive/natural language processing/assignment_2/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_x6j6G83Vn9",
        "outputId": "2d7098e1-3dc3-4b3d-bbfc-7c7d9a12f98b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read csv as data frame, and limit the columns that we require\n",
        "def read_source_csv_as_df(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df = df[['paper_id', 'title', 'authors', 'abstract', 'text']]\n",
        "    # replace NaN with empty string\n",
        "    df = df.fillna('')\n",
        "    return df"
      ],
      "metadata": {
        "id": "IKBH-xF-3e5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_json = read_source_csv_as_df(root_folder + 'pdf_json_clean.csv')\n"
      ],
      "metadata": {
        "id": "AU3qfFwz6kyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_json = pdf_json[0:5000]"
      ],
      "metadata": {
        "id": "zRgD_r85fx9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_json.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "Bbcd_aJF68ZN",
        "outputId": "0b324ca8-c2c0-42f7-c317-2422fe5a73b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   paper_id  \\\n",
              "0  8f97e16f3842e4bbd2d5d1c0c95ac1e31993ec68   \n",
              "1  8187ea360c53a56ca2c579d758a5d6aa67716836   \n",
              "2  a0d063dca746b135afe0451ce0b3bb1e06cf15ae   \n",
              "3  edb294108440787c9f074483fd3c953a83e53622   \n",
              "4  e0777fb5df224525ee1b06008582b084c1b6b13b   \n",
              "\n",
              "                                               title  \\\n",
              "0  An update on excess mortality in the second ye...   \n",
              "1                                                      \n",
              "2  Ethnic and regional variations in hospital mor...   \n",
              "3  Corona! Die Krise der Verschlankung und ihre F...   \n",
              "4  Association between central blood pressure, ar...   \n",
              "\n",
              "                                             authors  \\\n",
              "0  Asta Wirtsch, Sozialstat Arch, Giacomo De Nico...   \n",
              "1                                                      \n",
              "2  Núcleo De Astrofísica E Cosmologia, P Baqui, V...   \n",
              "3                      Z Arb,  Wiss, Irene Raehlmann   \n",
              "4  Feziwe Mpondo, Ashleigh Craig, Andrea Kolkenbe...   \n",
              "\n",
              "                                            abstract  \\\n",
              "0  Abstract\\n\\nIn this short note, we apply the m...   \n",
              "1                                                      \n",
              "2  Abstract\\n\\nBackground Brazil ranks second wor...   \n",
              "3                                                      \n",
              "4  Abstract\\n\\nThe burden of hypertension in Sout...   \n",
              "\n",
              "                                                text  \n",
              "0  \\n\\nExpected deaths by year, represented by bl...  \n",
              "1  COVID-19-negative psychiatric units: Mitigatin...  \n",
              "2  Introduction\\n\\nThe COVID-19 pandemic has crea...  \n",
              "3  Einleitung\\n\\nDie Corona-Pandemie ist eine Gef...  \n",
              "4  Introduction\\n\\nRaised blood pressure (BP) and...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c63c6d5-721d-477b-9f34-b7a4bf759643\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paper_id</th>\n",
              "      <th>title</th>\n",
              "      <th>authors</th>\n",
              "      <th>abstract</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8f97e16f3842e4bbd2d5d1c0c95ac1e31993ec68</td>\n",
              "      <td>An update on excess mortality in the second ye...</td>\n",
              "      <td>Asta Wirtsch, Sozialstat Arch, Giacomo De Nico...</td>\n",
              "      <td>Abstract\\n\\nIn this short note, we apply the m...</td>\n",
              "      <td>\\n\\nExpected deaths by year, represented by bl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8187ea360c53a56ca2c579d758a5d6aa67716836</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>COVID-19-negative psychiatric units: Mitigatin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a0d063dca746b135afe0451ce0b3bb1e06cf15ae</td>\n",
              "      <td>Ethnic and regional variations in hospital mor...</td>\n",
              "      <td>Núcleo De Astrofísica E Cosmologia, P Baqui, V...</td>\n",
              "      <td>Abstract\\n\\nBackground Brazil ranks second wor...</td>\n",
              "      <td>Introduction\\n\\nThe COVID-19 pandemic has crea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>edb294108440787c9f074483fd3c953a83e53622</td>\n",
              "      <td>Corona! Die Krise der Verschlankung und ihre F...</td>\n",
              "      <td>Z Arb,  Wiss, Irene Raehlmann</td>\n",
              "      <td></td>\n",
              "      <td>Einleitung\\n\\nDie Corona-Pandemie ist eine Gef...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>e0777fb5df224525ee1b06008582b084c1b6b13b</td>\n",
              "      <td>Association between central blood pressure, ar...</td>\n",
              "      <td>Feziwe Mpondo, Ashleigh Craig, Andrea Kolkenbe...</td>\n",
              "      <td>Abstract\\n\\nThe burden of hypertension in Sout...</td>\n",
              "      <td>Introduction\\n\\nRaised blood pressure (BP) and...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c63c6d5-721d-477b-9f34-b7a4bf759643')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c63c6d5-721d-477b-9f34-b7a4bf759643 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c63c6d5-721d-477b-9f34-b7a4bf759643');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pdf_json = pdf_json[0:100]"
      ],
      "metadata": {
        "id": "S2Z_c31pAeWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = list(pdf_json['text'])\n",
        "y = list(pdf_json['abstract'])\n",
        "\n",
        "print('len of X ', len(X))\n",
        "print('len of y ', len(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohcYfAef7WEm",
        "outputId": "a0ef004c-7e4d-4783-f199-c72e907eb1d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len of X  5000\n",
            "len of y  5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "svzaODSQ7MtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of X_train ', len(X_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTvqKuU_7zil",
        "outputId": "b69a497f-0997-4fc3-b132-f735084b8047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train  3350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # use built-in summarizer\n",
        "# from transformers import pipeline\n",
        "# summarizer = pipeline(\"summarization\")\n",
        "# text = '''Once you have a dataset, you can use supervised machine learning algorithms such as decision trees, random forests, or neural networks to train a text summarization model. You will need to label the data with summaries that you want the model to learn to produce. One approach is to manually create the summaries for a subset of the data and then use these labeled examples to train the model. You can then use the trained model to generate summaries for new, unseen data.\n",
        "\n",
        "# Keep in mind that supervised machine learning algorithms require a large amount of labeled data to achieve good performance. If you do not have access to a large labeled dataset, you may need to consider other approaches, such as unsupervised learning or transfer learning.'''\n",
        "\n",
        "# summary = summarizer(text)\n",
        "# print('summary ', summary)"
      ],
      "metadata": {
        "id": "wQi2Oho_GAMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "\n",
        "model_name = 't5-small'\n",
        "model = transformers.AutoModelWithLMHead.from_pretrained(model_name)\n",
        "\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "nlp_summarizer = transformers.pipeline('summarization', model = model, tokenizer = tokenizer)\n",
        "\n",
        "nlp_summarizer(pdf_json.iloc[0]['text'])\n",
        "\n",
        "# nlp_fill = transformers.pipeline('fill-mask', model = model, tokenizer = tokenizer)\n",
        "# nlp_fill('Coronavirus or COVID-19 can be prevented by a' + nlp_fill.tokenizer.mask_token)\n",
        "\n",
        "# Output:\n",
        "# [{'sequence': '[CLS] coronavirus or covid - 19 can be prevented by a combination [SEP]',\n",
        "#   'score': 0.1719885915517807,\n",
        "#   'token': 2702},\n",
        "#  {'sequence': '[CLS] coronavirus or covid - 19 can be prevented by a simple [SEP]',\n",
        "#   'score': 0.054218728095293045,\n",
        "#   'token': 2177},\n",
        "#  {'sequence': '[CLS] coronavirus or covid - 19 can be prevented by a novel [SEP]',\n",
        "#   'score': 0.043364267796278,\n",
        "#   'token': 3045},\n",
        "#  {'sequence': '[CLS] coronavirus or covid - 19 can be prevented by a high [SEP]',\n",
        "#   'score': 0.03732519596815109,\n",
        "#   'token': 597},\n",
        "#  {'sequence': '[CLS] coronavirus or covid - 19 can be prevented by a vaccine [SEP]',\n",
        "#   'score': 0.021863549947738647,\n",
        "#   'token': 7039}]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4kRqaIdWGgy",
        "outputId": "716faa45-43e1-4240-e252-7da755d20f35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/models/auto/modeling_auto.py:1295: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (841 > 512). Running this sequence through the model will result in indexing errors\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1201: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': 'global excess mortality in 2021 was more pronounced than in 2020 . a total of 1 019 809 deaths were registered in Germany for the year 2021 . this corresponds to an estimated overall excess mortality of approximately 2.3% .'}]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # use built-in summarizer\n",
        "# from transformers import pipeline\n",
        "# summarizer = pipeline(\"summarization\")\n",
        "# text = '''Once you have a dataset, you can use supervised machine learning algorithms such as decision trees, random forests, or neural networks to train a text summarization model. You will need to label the data with summaries that you want the model to learn to produce. One approach is to manually create the summaries for a subset of the data and then use these labeled examples to train the model. You can then use the trained model to generate summaries for new, unseen data.\n",
        "\n",
        "# Keep in mind that supervised machine learning algorithms require a large amount of labeled data to achieve good performance. If you do not have access to a large labeled dataset, you may need to consider other approaches, such as unsupervised learning or transfer learning.'''\n",
        "\n",
        "# summary = summarizer(text)\n",
        "# print('summary ', summary)"
      ],
      "metadata": {
        "id": "g-te-LGZWBn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0GGbtMCVV_qD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = pd.DataFrame({'article' : X_train, 'highlights' : y_train})"
      ],
      "metadata": {
        "id": "FP-IGbIiHhP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qqWgzg0uHrcM",
        "outputId": "8ea0ea62-3ba6-4345-e633-fc996c93860a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             article  \\\n",
              "0  22\\n\\nNeurological dysfunction has been noted ...   \n",
              "1  Introduction\\n\\nVarious genera of respiratory ...   \n",
              "2  Introduction\\n\\nConventionally, only specializ...   \n",
              "3  \\n\\nBoth diabetes and obesity are related to p...   \n",
              "4  INTRODUC TI ON\\n\\nThe coronavirus (COVID- 19) ...   \n",
              "\n",
              "                                          highlights  \n",
              "0                                                     \n",
              "1  Abstract\\n\\nBackground: The traditional Serfli...  \n",
              "2  Abstract\\n\\nRNA interference (RNAi), initially...  \n",
              "3  Abstract\\n\\nBoth diabetes and obesity are rela...  \n",
              "4  Abstract\\n\\nThis is an open access article und...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4be952f-9e95-4585-96b9-947a8cb01cb7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>highlights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22\\n\\nNeurological dysfunction has been noted ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Introduction\\n\\nVarious genera of respiratory ...</td>\n",
              "      <td>Abstract\\n\\nBackground: The traditional Serfli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Introduction\\n\\nConventionally, only specializ...</td>\n",
              "      <td>Abstract\\n\\nRNA interference (RNAi), initially...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\n\\nBoth diabetes and obesity are related to p...</td>\n",
              "      <td>Abstract\\n\\nBoth diabetes and obesity are rela...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>INTRODUC TI ON\\n\\nThe coronavirus (COVID- 19) ...</td>\n",
              "      <td>Abstract\\n\\nThis is an open access article und...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4be952f-9e95-4585-96b9-947a8cb01cb7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d4be952f-9e95-4585-96b9-947a8cb01cb7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d4be952f-9e95-4585-96b9-947a8cb01cb7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import datasets\n",
        "\n",
        "# # Load 1% of the training/validation sets.\n",
        "# train_data      = datasets.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train[0:1%]\")\n",
        "# validation_data = datasets.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"validation[0:1%]\")"
      ],
      "metadata": {
        "id": "QBzGJX2QUQ3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyarrow as pa\n",
        "import pyarrow.dataset as ds\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "### convert to Huggingface dataset\n",
        "train_data = Dataset(pa.Table.from_pandas(examples))"
      ],
      "metadata": {
        "id": "6kqkiYnqY_km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZFKeE7mZIlc",
        "outputId": "77d1f987-486b-4e01-8401-89159aa50986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datasets.arrow_dataset.Dataset"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartTokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "article_length = 512\n",
        "summary_length = 64\n",
        "batch_size     = 4\n",
        "\n",
        "# Load the BART's pre-trained Tokenizer\n",
        "# TODO use pretrained model for medical data, covid would be best\n",
        "# tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "# Define the function to make the correct data structure\n",
        "def process_data_to_model_inputs(batch):\n",
        "  # tokenize the inputs and labels\n",
        "  inputs = tokenizer(batch[\"article\"], padding=\"max_length\", truncation=True, max_length=article_length)\n",
        "  outputs = tokenizer(batch[\"highlights\"], padding=\"max_length\", truncation=True, max_length=summary_length)\n",
        "\n",
        "  batch[\"input_ids\"] = inputs.input_ids\n",
        "  batch[\"attention_mask\"] = inputs.attention_mask\n",
        "  batch[\"decoder_input_ids\"] = outputs.input_ids\n",
        "  batch[\"decoder_attention_mask\"] = outputs.attention_mask\n",
        "  batch[\"labels\"] = outputs.input_ids.copy()\n",
        "\n",
        "  # We have to make sure that the PAD token is ignored for calculating the loss\n",
        "  batch[\"labels\"] = [[-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]]\n",
        "\n",
        "  return batch\n",
        "\n",
        "# Map the function to both train/validation sets.\n",
        "train_data = train_data.map(\n",
        "    process_data_to_model_inputs, \n",
        "    batched=True,\n",
        "    remove_columns=[\"article\", \"highlights\"]\n",
        ")\n",
        "\n",
        "# Convert the Dataset to PyTorch tensor with the expected columns\n",
        "train_data.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\",\n",
        "                           \"decoder_attention_mask\", \"labels\"],\n",
        ")\n",
        "\n",
        "# Make the iterative object that does batching using the DataLoader\n",
        "train_data      = DataLoader(train_data, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147,
          "referenced_widgets": [
            "ced10323ca41432880435061d2390132",
            "be85d98fe7dc4d0993074d6d7de502c6",
            "7f3e20ad5d53428a8e1096fda6e6323d",
            "601c3867edfb44f5a963e73195450f44",
            "70eba14f52894e7a93096e4f936349d8",
            "56c62632281246a4bc62a853af6349b4",
            "9706e64eb5e04bac81e5fd1096dcd68a",
            "da48a1175bdb46258caba910468761ae",
            "fdb1d8ddd17047fdad1f36a8ee3190cd",
            "18fb17b671cb4fdab3e43f6f1b7dd930",
            "5e4e2332268b49339fc7a026419a55de"
          ]
        },
        "id": "3KW4wRMaR0G1",
        "outputId": "b1615c23-97d1-43df-9440-70f6cc857f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3350 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ced10323ca41432880435061d2390132"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data"
      ],
      "metadata": {
        "id": "rlBV-8QcZVdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration\n",
        "import torch\n",
        "#https://pub.towardsai.net/how-to-train-a-seq2seq-text-summarization-model-with-sample-code-ft-huggingface-pytorch-8ba97492f885\n",
        "# Load the model\n",
        "# model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "model = transformers.AutoModelWithLMHead.from_pretrained(model_name)\n",
        "\n",
        "# Put the model on GPU\n",
        "if torch.cuda.is_available():\n",
        "  model = model.to(\"cuda\")\n",
        "  print('using gpu')\n",
        "\n",
        "# Split model's components\n",
        "the_encoder = model.get_encoder()\n",
        "the_decoder = model.get_decoder()\n",
        "last_linear_layer = model.lm_head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnmMGeE9ZfWU",
        "outputId": "793941c1-536b-48dc-f035-9946645b8aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/models/auto/modeling_auto.py:1295: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using gpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "from transformers import AdamW\n",
        "from transformers import get_scheduler\n",
        "\n",
        "num_epochs = 20\n",
        "num_training_steps = num_epochs * len(train_data)\n",
        "\n",
        "# The loss function\n",
        "loss_fct = CrossEntropyLoss()\n",
        "\n",
        "# The optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=0.001)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8K2cWdcZrdk",
        "outputId": "e3e3a903-1dc2-45ea-c605-a526a7dae3e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print('epoch number ', epoch)\n",
        "    model.train()\n",
        "    for batch in train_data:\n",
        "      if torch.cuda.is_available():\n",
        "        batch = {k: v.to('cuda') for k, v in batch.items()}\n",
        "\n",
        "      # Get the \"input's representation\"\n",
        "      encoder_output = the_encoder(input_ids = batch['input_ids'],\n",
        "                                   attention_mask = batch['attention_mask'])\n",
        "      \n",
        "      # Pass the representation + the target summary to the decoder\n",
        "      decoder_output = the_decoder(input_ids=batch['decoder_input_ids'],\n",
        "                                   attention_mask=batch['decoder_attention_mask'],\n",
        "                                   encoder_hidden_states=encoder_output[0],\n",
        "                                   encoder_attention_mask=batch['attention_mask'])\n",
        "\n",
        "      # Use the last linear layer to predict the next token\n",
        "      decoder_output = decoder_output.last_hidden_state\n",
        "      lm_head_output = last_linear_layer(decoder_output)\n",
        "      \n",
        "      # Compute the loss\n",
        "      loss = loss_fct(lm_head_output.view(-1, model.config.vocab_size),\n",
        "                      batch['labels'].view(-1))\n",
        "      \n",
        "      loss.backward() # Update the weights\n",
        "      optimizer.step() # Notify optimizer that a batch is done.\n",
        "      lr_scheduler.step() # Notify the scheduler that a ...\n",
        "      optimizer.zero_grad() # Reset the optimer\n",
        "\n",
        "\n",
        "print('End of training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7NnyzA0ZzSO",
        "outputId": "60ad4e28-2f92-4ba9-d3fd-00e85e1d4ffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch number  0\n",
            "epoch number  1\n",
            "epoch number  2\n",
            "epoch number  3\n",
            "epoch number  4\n",
            "epoch number  5\n",
            "epoch number  6\n",
            "epoch number  7\n",
            "epoch number  8\n",
            "epoch number  9\n",
            "epoch number  10\n",
            "epoch number  11\n",
            "epoch number  12\n",
            "epoch number  13\n",
            "epoch number  14\n",
            "epoch number  15\n",
            "epoch number  16\n",
            "epoch number  17\n",
            "epoch number  18\n",
            "epoch number  19\n",
            "End of training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples_val = pd.DataFrame({'article' : X_test, 'highlights' : y_test})\n",
        "validation_data = Dataset(pa.Table.from_pandas(examples_val))"
      ],
      "metadata": {
        "id": "-13G5zDnaXe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validation_data"
      ],
      "metadata": {
        "id": "KQSgdI39aq2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data = validation_data.map(\n",
        "    process_data_to_model_inputs, \n",
        "    batched=True,\n",
        "    remove_columns=[\"article\", \"highlights\"]\n",
        ")\n",
        "\n",
        "# Convert the Dataset to PyTorch tensor with the expected columns\n",
        "validation_data.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\",\n",
        "                           \"decoder_attention_mask\", \"labels\"],\n",
        ")\n",
        "\n",
        "# Make the iterative object that does batching using the DataLoader\n",
        "validation_data = DataLoader(validation_data, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "l5UAJBf4bhXs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "dd1b01888602451282b9a66aeb4a00c1",
            "4c46702c22514e13acdad91f5ba1aef6",
            "ca26d2add161463c9e90e2b2e4110b03",
            "e770c4b74e4c47e3816e9c7da4c0f067",
            "181cdb5c2bbe46648833256762a5b35e",
            "18205b78a8c14ecdb4e5a55a4dab7818",
            "3b32db36043e423a856525994bbe6020",
            "d790d07432004c03951005e9d39bdf41",
            "afea395045ce4854962139463bc963f0",
            "d2d9a7bf41fb467ebd1442c44b7e7e63",
            "65a8a3d88e7e49b4a9cdc07b942bfc80"
          ]
        },
        "outputId": "de760c10-4dec-4b89-f51c-503bcbf626a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1650 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd1b01888602451282b9a66aeb4a00c1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# validation_data"
      ],
      "metadata": {
        "id": "SzxY-y66bpc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.eval()\n",
        "for batch in validation_data:\n",
        "    if torch.cuda.is_available():\n",
        "        # print('batch ', batch)\n",
        "        # for k, v in batch.items():\n",
        "            # print('k ', k)\n",
        "            # print('v ', v)\n",
        "        batch = {k: v.to('cuda') for k, v in batch.items()}\n",
        "        \n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "\n",
        "    # print('outputs ', outputs)\n",
        "    loss = outputs.loss\n",
        "    # print('loss ', loss)\n",
        "    # fds"
      ],
      "metadata": {
        "id": "O3WneNjXaP1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_json.iloc[0]['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "zv1mm0OfF6ox",
        "outputId": "ca919120-318d-4d07-999b-e4ce09cd162c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\nExpected deaths by year, represented by blue squares, plotted against observed fatalities, depicted by black dots. Overall excess mortality in 2021 was more pronounced than in 2020In our article (De Nicola et al. 2022) in this issue, we presented a simple and novel method to compute excess mortality in a given calendar year while effectively taking the age structure of the population into account. We then applied our method to age-stratified mortality data to obtain estimates for general and age group-specific excess mortality for Germany in 2020, the first year of the COVID-19 pandemic. As we enter 2022, mortality figures from 2021 are starting to become available. With this short note, we thereby aim to provide the reader with up-to-date estimates of excess mortality for the second consecutive year of the pandemic. Mortality data are provided by the German Federal Statistical Office (Destatis 2022). Figures for 2021 are, at time point of submission of this note, not final, and numbers will presumably increase due to data corrections. We leave this problem aside here, and work with data as of February 1, 2022. Fig. 1 gives an overview of the results for all age groups combined. We plot the expected death counts for each year as blue squares (see De Nicola et al. 2022 for details), and the observed death counts as black dots. We can see that overall excess mortality in 2021 was more pronounced than in 2020. More specifically, as of February 1, 2022, a total of 1 019 809 deaths were registered in Germany for the year 2021, i.e. 23 399 deaths more than expected. This corresponds to an estimated overall excess mortality of approximately 2.3%. Table 1 and Fig. 2 give a more complete picture of the mortality observed in 2021 for the different age groups. We observe that the most pronounced relative excess mortality was observed in the age groups 40-50, 60-70 and 70-80. We can also see how, in general, excess mortality was more driven by deaths in the 60-79 age category rather than in the 80+ group.As a concluding note, we emphasise that all results presented here are based on provisional data, as the final death tolls for 2021 in Germany are not yet available at the time of writing. We can therefore expect some more deaths to be registered in the coming months. Based on past experience, those late registration should produce an increase of a few thousand units in the final toll (last year 982 489 deaths were registered for 2020 as of January 29, 2021, while the final, official toll amounted to 985 572). All in all, we can conclude that excess mortality for 2021 in Germany can, with data up to February 1, 2022, be estimated at a minimum of 2.3%, and that the final estimate will most likely be higher by a few decimal points.Funding Open Access funding enabled and organized by Projekt DEAL.Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4. 0/.\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
        "\n",
        "model_new = transformers.AutoModelWithLMHead.from_pretrained(model_name)\n",
        "# model_new = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "# Put the model on GPU\n",
        "if torch.cuda.is_available():\n",
        "    model_new = model_new.to(\"cuda\")\n",
        "    print('using gpu')\n",
        "\n",
        "# ARTICLE_TO_SUMMARIZE = (\n",
        "#     \"PG&E stated it scheduled the blackouts in response to forecasts for high winds \"\n",
        "#     \"amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were \"\n",
        "#     \"scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\n",
        "# )\n"
      ],
      "metadata": {
        "id": "ECWemzwScBUE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "286705ac-0ddb-42ef-b41d-ef1923b17306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using gpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_json.iloc[0]['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "ewNyG_iiGZ7B",
        "outputId": "49d3f9f8-41f2-4bed-ffaa-c9c442c133a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\nExpected deaths by year, represented by blue squares, plotted against observed fatalities, depicted by black dots. Overall excess mortality in 2021 was more pronounced than in 2020In our article (De Nicola et al. 2022) in this issue, we presented a simple and novel method to compute excess mortality in a given calendar year while effectively taking the age structure of the population into account. We then applied our method to age-stratified mortality data to obtain estimates for general and age group-specific excess mortality for Germany in 2020, the first year of the COVID-19 pandemic. As we enter 2022, mortality figures from 2021 are starting to become available. With this short note, we thereby aim to provide the reader with up-to-date estimates of excess mortality for the second consecutive year of the pandemic. Mortality data are provided by the German Federal Statistical Office (Destatis 2022). Figures for 2021 are, at time point of submission of this note, not final, and numbers will presumably increase due to data corrections. We leave this problem aside here, and work with data as of February 1, 2022. Fig. 1 gives an overview of the results for all age groups combined. We plot the expected death counts for each year as blue squares (see De Nicola et al. 2022 for details), and the observed death counts as black dots. We can see that overall excess mortality in 2021 was more pronounced than in 2020. More specifically, as of February 1, 2022, a total of 1 019 809 deaths were registered in Germany for the year 2021, i.e. 23 399 deaths more than expected. This corresponds to an estimated overall excess mortality of approximately 2.3%. Table 1 and Fig. 2 give a more complete picture of the mortality observed in 2021 for the different age groups. We observe that the most pronounced relative excess mortality was observed in the age groups 40-50, 60-70 and 70-80. We can also see how, in general, excess mortality was more driven by deaths in the 60-79 age category rather than in the 80+ group.As a concluding note, we emphasise that all results presented here are based on provisional data, as the final death tolls for 2021 in Germany are not yet available at the time of writing. We can therefore expect some more deaths to be registered in the coming months. Based on past experience, those late registration should produce an increase of a few thousand units in the final toll (last year 982 489 deaths were registered for 2020 as of January 29, 2021, while the final, official toll amounted to 985 572). All in all, we can conclude that excess mortality for 2021 in Germany can, with data up to February 1, 2022, be estimated at a minimum of 2.3%, and that the final estimate will most likely be higher by a few decimal points.Funding Open Access funding enabled and organized by Projekt DEAL.Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4. 0/.\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ARTICLE_TO_SUMMARIZE = (pdf_json.iloc[0]['text'])\n",
        "\n",
        "inputs = tokenizer([ARTICLE_TO_SUMMARIZE], return_tensors=\"pt\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    inputs = {k: v.to('cuda') for k, v in inputs.items()}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EVsxwNaGKUY",
        "outputId": "f9b72f92-4501-444a-d957-3e22b38fd227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Summary using pre-trained model without further training\n",
        "summary_ids_new = model_new.generate(inputs[\"input_ids\"], num_beams=2, min_length=0, max_length=500)\n",
        "tokenizer.batch_decode(summary_ids_new, skip_special_tokens=True, clean_up_tokenization_spaces=False)"
      ],
      "metadata": {
        "id": "HZKWMhF0lDct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f30a0b3-5ef9-455a-bee5-602d68f17de2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['in the year 2021, i.e. 23 399 deaths more than expected . Fig. 1 gives an overview of the results for all age groups combined . we plot the expected death counts for each year as blue squares, and the observed death counts as black dots . figures for 2021 are, at time point of submission of this note, not final, and numbers will presumably increase due to data corrections .']"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Summary using custom trained model\n",
        "summary_ids = model.generate(inputs[\"input_ids\"], num_beams=2, min_length=0, max_length=500)\n",
        "tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
      ],
      "metadata": {
        "id": "XyVXzEMCmWuc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "d2d4d25c-ecdb-4be0-af84-81e3f4dd1414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Der Der Der Der der der der der der der der der der der der der der der der des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des Des'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    }
  ]
}